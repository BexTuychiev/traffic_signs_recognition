{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad05b10-c25e-49ff-a29c-a3430389e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39209 images belonging to 43 classes.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the paths to the train and validation directories\n",
    "train_dir = Path(\"../data/raw/train/\")\n",
    "\n",
    "# Create an ImageDataGenerator object for the train set\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values\n",
    "    rotation_range=45,  # Randomly rotate images\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically\n",
    "    zoom_range=0.2,  # Randomly zoom in and out of images\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode=\"nearest\",  # Fill in missing pixels with nearest neighbor\n",
    ")\n",
    "\n",
    "# Generate training data from the train directory\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    train_dir,  # Target directory\n",
    "    target_size=(30, 30),  # Resize images to 150x150\n",
    "    batch_size=64,  # Set batch size\n",
    "    class_mode=\"categorical\",  # Use categorical labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82fef35-b5d7-457a-84f6-b0dcb8f03b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 4s 34ms/step - loss: 3.3179 - accuracy: 0.1080\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 2.8876 - accuracy: 0.1858\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 2.6404 - accuracy: 0.2445\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.4595 - accuracy: 0.2844\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.3434 - accuracy: 0.3120\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.1752 - accuracy: 0.3596\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 3s 32ms/step - loss: 2.0577 - accuracy: 0.3746\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.9211 - accuracy: 0.4069\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.8832 - accuracy: 0.4220\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 3s 31ms/step - loss: 1.7556 - accuracy: 0.4493\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(30, 30, 3)),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(43, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",  # Use categorical cross-entropy loss\n",
    "    optimizer=tf.keras.optimizers.Adam(),  # Use Adam optimizer\n",
    "    metrics=[\"accuracy\"],  # Calculate accuracy\n",
    ")\n",
    "\n",
    "# Fit the model to the train data\n",
    "history = model.fit(\n",
    "    train_generator,  # Training data\n",
    "    steps_per_epoch=100,  # Number of steps per epoch\n",
    "    epochs=10,  # Number of epochs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "traffic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
